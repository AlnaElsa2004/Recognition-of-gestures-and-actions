{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This project focuses on implementing a system for recognizing gestures and movements in videos and images using a pre-trained deep learning model, enabling applications such as pose estimation, activity monitoring, and gesture-based interactions."
      ],
      "metadata": {
        "id": "HssHony8z-C9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detecting body points"
      ],
      "metadata": {
        "id": "KteztrudKwrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the libraries"
      ],
      "metadata": {
        "id": "PHnXA0RQK1Dc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_-5oDyXKpuT"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the image"
      ],
      "metadata": {
        "id": "FJL8D1T2LQKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Q-wtUVXXLOVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/my_new_folder"
      ],
      "metadata": {
        "id": "lv9GP2IpLZTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=cv2.imread('/content/my_new_folder/megan.jpg')"
      ],
      "metadata": {
        "id": "F-g9nrouLmgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "u7K5uTzzL5r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape,image.shape[0]*image.shape[1]*3"
      ],
      "metadata": {
        "id": "_IK9tdF1L7ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_blob=cv2.dnn.blobFromImage(image=image,scalefactor=1.0/255,size=(image.shape[1],image.shape[0]))  #converting image to blob"
      ],
      "metadata": {
        "id": "jQCXQ4a1L-dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(image_blob),image_blob.shape #batch format 1-only one image"
      ],
      "metadata": {
        "id": "rIRT85LCMjB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the pre-trained neural network"
      ],
      "metadata": {
        "id": "E2ysvz4YMwPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network=cv2.dnn.readNetFromCaffe('/content/my_new_folder/pose_deploy_linevec_faster_4_stages.prototxt','/content/my_new_folder/pose_iter_160000.caffemodel') #neural network was loaded"
      ],
      "metadata": {
        "id": "VYobM0cvMlyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network.getLayerNames() #lists the name of layers"
      ],
      "metadata": {
        "id": "e102hzCyNOk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(network.getLayerNames())"
      ],
      "metadata": {
        "id": "K-Ft4QMxOrU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting body points"
      ],
      "metadata": {
        "id": "ny84OULbO3aL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network.setInput(image_blob)\n",
        "output=network.forward() #so the image will go to input layer and pass through all convolutional and pooling layers and finally reach the output layer"
      ],
      "metadata": {
        "id": "Jkf2-kpTO1d8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "id": "-vMNEkF5PYiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "position_width=output.shape[3]\n",
        "position_height=output.shape[2]"
      ],
      "metadata": {
        "id": "gCmoAzAUPc5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "position_width"
      ],
      "metadata": {
        "id": "k6WVHG8bP1JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_points=15 #no of points\n",
        "points=[]\n",
        "for i in range(num_points):\n",
        "  confidence_map=output[0,i,:,:]\n",
        "  print(confidence_map)\n",
        "  print(len(confidence_map))# so the neural networks will return 43 candidate points for each one of the points and we need to find the maximum value among them inorder to get the best one (the value with high confidence)\n",
        ""
      ],
      "metadata": {
        "id": "24VX4t4hP4c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_points=15 #no of points\n",
        "points=[]\n",
        "threshold=0.1\n",
        "for i in range(num_points):\n",
        "  confidence_map=output[0,i,:,:]\n",
        "  #print(confidence_map)\n",
        "  #print(len(confidence_map))# so the neural networks will return 43 candidate points for each one of the points and we need to find the maximum value among them inorder to get the best one (the value with high confidence)\n",
        "  _,confidence,_,point=cv2.minMaxLoc(confidence_map)  #to find the maximum value and point\n",
        "  #print(confidence)\n",
        "  #print(point)\n",
        "\n",
        "  x=int((image.shape[1]*point[0])/position_width)\n",
        "  y=int((image.shape[0]*point[1])/position_height)\n",
        "  if confidence>threshold:\n",
        "    cv2.circle(image,(x,y),5,(0,255,0),thickness=-1)\n",
        "    cv2.putText(image,'{}'.format(i),(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255))\n",
        "    points.append((x,y))\n",
        "  else:\n",
        "    points.append(None)\n",
        "\n"
      ],
      "metadata": {
        "id": "V3wTbljJRGs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "points"
      ],
      "metadata": {
        "id": "BimSDvuYRkbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drawing points in the image\n",
        "plt.figure(figsize=(14,10))\n",
        "plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB));"
      ],
      "metadata": {
        "id": "vmltrbqWTF7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To draw lines connecting each points\n",
        "point_connections=[[0,1],[1,2],[2,3],[3,4],[1,5],[5,6],[6,7],[1,14],[14,8],[8,9],[9,10],[14,11],[11,12],[12,13]]"
      ],
      "metadata": {
        "id": "hbIYiC6nTeAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "point_connections"
      ],
      "metadata": {
        "id": "R_x2HIepUVoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for connection in point_connections:\n",
        "  partA=connection[0]\n",
        "  partB=connection[1]\n",
        "  if points[partA] and points[partB]:\n",
        "    cv2.line(image,points[partA],points[partB],(255,0,0))"
      ],
      "metadata": {
        "id": "_X_Lqq3WUXqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying the image\n",
        "plt.figure(figsize=(14,10))\n",
        "plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB));"
      ],
      "metadata": {
        "id": "3gGkaSqfVZa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detecting movements(arms above the head)"
      ],
      "metadata": {
        "id": "I0A6HxNmjKSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arms above the head in images"
      ],
      "metadata": {
        "id": "hNEjCtDhjcnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image2=cv2.imread('/content/my_new_folder/player.jpg')\n",
        "cv2_imshow(image2)"
      ],
      "metadata": {
        "id": "jTOt_jnnVh4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_blob2=cv2.dnn.blobFromImage(image=image2,scalefactor=1.0/255,size=(image2.shape[1],image2.shape[0]))  #converting image to blob\n",
        "network.setInput(image_blob2)\n",
        "output2=network.forward()\n",
        "position_width=output2.shape[3]\n",
        "position_height=output2.shape[2]\n",
        "num_points=15 #no of points\n",
        "points=[]\n",
        "threshold=0.1\n",
        "for i in range(num_points):\n",
        "  confidence_map=output2[0,i,:,:]\n",
        "  #print(confidence_map)\n",
        "  #print(len(confidence_map))# so the neural networks will return 43 candidate points for each one of the points and we need to find the maximum value among them inorder to get the best one (the value with high confidence)\n",
        "  _,confidence,_,point=cv2.minMaxLoc(confidence_map)  #to find the maximum value and point\n",
        "  #print(confidence)\n",
        "  #print(point)\n",
        "\n",
        "  x=int((image2.shape[1]*point[0])/position_width)\n",
        "  y=int((image2.shape[0]*point[1])/position_height)\n",
        "  if confidence>threshold:\n",
        "    cv2.circle(image2,(x,y),3,(0,255,0),thickness=-1)\n",
        "    cv2.putText(image2,'{}'.format(i),(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.3,(0,0,255))\n",
        "    cv2.putText(image2,'{}-{}'.format(point[0],point[1]),(x,y+10),cv2.FONT_HERSHEY_SIMPLEX,.5,(255,0,255))\n",
        "    points.append((x,y))\n",
        "  else:\n",
        "    points.append(None)\n",
        "plt.figure(figsize=[14,10])\n",
        "plt.imshow(cv2.cvtColor(image2,cv2.COLOR_BGR2RGB));\n"
      ],
      "metadata": {
        "id": "CUGJBW4-j7_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the figure while moving from top to bottom the value increases and if we move from left to right the value decreases"
      ],
      "metadata": {
        "id": "QWoItFBXm8iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_arms_up(points):\n",
        "  head,right_wrist,left_wrist=0,0,0\n",
        "  for i,point in enumerate(points):\n",
        "    if i==0:\n",
        "      head=point[1]\n",
        "    elif i==4:\n",
        "      right_wrist=point[1]\n",
        "    elif i==7:\n",
        "      left_wrist=point[1]\n",
        "  if right_wrist<head and left_wrist<head:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "metadata": {
        "id": "PCJIa3dblLjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verify_arms_up(points)"
      ],
      "metadata": {
        "id": "DXt8-9RtnvTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So both arms are above the head"
      ],
      "metadata": {
        "id": "en9ze6vyn1RD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arms above the head in videos"
      ],
      "metadata": {
        "id": "0m4Au7_WoBlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video='/content/my_new_folder/gesture1.mp4'\n",
        "capture=cv2.VideoCapture(video)\n",
        "connected,frame=capture.read()"
      ],
      "metadata": {
        "id": "5X7coR_Mnykj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "connected"
      ],
      "metadata": {
        "id": "gxcAPiikocxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame.shape"
      ],
      "metadata": {
        "id": "l-p3UWYeofen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result='/content/my_new_folder/gesture1_result.mp4'\n",
        "save_video=cv2.VideoWriter(result,cv2.VideoWriter_fourcc(*'XVID'),10,(frame.shape[1],frame.shape[0]))"
      ],
      "metadata": {
        "id": "ZhBFySZjo8E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold=0.1\n",
        "while cv2.waitKey(1)<0:\n",
        "  connected,frame=capture.read()\n",
        "\n",
        "  if not connected:\n",
        "    break\n",
        "\n",
        "  image_blob=cv2.dnn.blobFromImage(image=frame,scalefactor=1.0/255,size=(256,256))  #converting image to blob\n",
        "  network.setInput(image_blob)\n",
        "  output=network.forward()\n",
        "  position_width=output.shape[3]\n",
        "  position_height=output.shape[2]\n",
        "  num_points=15 #no of points\n",
        "  points=[]\n",
        "\n",
        "  for i in range(num_points):\n",
        "    confidence_map=output[0,i,:,:]\n",
        "  #print(confidence_map)\n",
        "  #print(len(confidence_map))# so the neural networks will return 43 candidate points for each one of the points and we need to find the maximum value among them inorder to get the best one (the value with high confidence)\n",
        "    _,confidence,_,point=cv2.minMaxLoc(confidence_map)  #to find the maximum value and point\n",
        "  #print(confidence)\n",
        "  #print(point)\n",
        "\n",
        "    x=int((frame.shape[1]*point[0])/position_width)\n",
        "    y=int((frame.shape[0]*point[1])/position_height)\n",
        "    if confidence>threshold:\n",
        "      cv2.circle(frame,(x,y),5,(0,255,0),thickness=-1)\n",
        "      cv2.putText(frame,'{}'.format(i),(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255))\n",
        "\n",
        "      points.append((x,y))\n",
        "    else:\n",
        "      points.append(None)\n",
        "\n",
        "  for connection in point_connections:\n",
        "    partA=connection[0]\n",
        "    partB=connection[1]\n",
        "    if points[partA] and points[partB]:\n",
        "      cv2.line(frame,points[partA],points[partB],(255,0,0))\n",
        "  if verify_arms_up(points) == True:\n",
        "    cv2.putText(frame,'Complete',(50,200),cv2.FONT_HERSHEY_COMPLEX,3,(0,0,255))\n",
        "\n",
        "  cv2_imshow(frame)  #So here we are accessing frame by frame of this video\n",
        "  save_video.write(frame)\n",
        "save_video.release()"
      ],
      "metadata": {
        "id": "QG_cc8NlpjzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detecting movements(legs are apart)"
      ],
      "metadata": {
        "id": "dH6bmMjOvSl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Considering images"
      ],
      "metadata": {
        "id": "MzhQnd_lvbTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image=cv2.imread('/content/my_new_folder/jump.jpg')\n",
        "image_blob=cv2.dnn.blobFromImage(image=image,scalefactor=1.0/255,size=(image.shape[1],image.shape[0]))  #converting image to blob\n",
        "network.setInput(image_blob)\n",
        "output=network.forward()\n",
        "position_width=output.shape[3]\n",
        "position_height=output.shape[2]\n",
        "num_points=15 #no of points\n",
        "points=[]\n",
        "threshold=0.1\n",
        "for i in range(num_points):\n",
        "  confidence_map=output[0,i,:,:]\n",
        "  #print(confidence_map)\n",
        "  #print(len(confidence_map))# so the neural networks will return 43 candidate points for each one of the points and we need to find the maximum value among them inorder to get the best one (the value with high confidence)\n",
        "  _,confidence,_,point=cv2.minMaxLoc(confidence_map)  #to find the maximum value and point\n",
        "  #print(confidence)\n",
        "  #print(point)\n",
        "\n",
        "  x=int((image.shape[1]*point[0])/position_width)\n",
        "  y=int((image.shape[0]*point[1])/position_height)\n",
        "  if confidence>threshold:\n",
        "    cv2.circle(image,(x,y),3,(0,255,0),thickness=-1)\n",
        "    cv2.putText(image,'{}'.format(i),(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.2,(0,0,255))\n",
        "    cv2.putText(image,'{}-{}'.format(point[0],point[1]),(x,y+10),cv2.FONT_HERSHEY_SIMPLEX,.5,(255,0,255))\n",
        "    points.append((x,y))\n",
        "  else:\n",
        "    points.append(None)\n",
        "plt.figure(figsize=[14,10])\n",
        "plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB));\n"
      ],
      "metadata": {
        "id": "Ce3lChMQqEgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the figure while moving from left to right the value increases and if we move from top to bottom the value decreases"
      ],
      "metadata": {
        "id": "nJScwqMQxdcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_legs_apart(points):\n",
        "  left_hip,right_hip=0,0\n",
        "  left_ankle,right_ankle=0,0\n",
        "  for i,point in enumerate(points):\n",
        "    if i==11:\n",
        "      left_hip=point[0]\n",
        "    elif i==8:\n",
        "      right_hip=point[0]\n",
        "    elif i==13:\n",
        "      left_ankle=point[0]\n",
        "    elif i==10:\n",
        "      right_ankle=point[0]\n",
        "  if (left_ankle>left_hip) and(right_ankle<right_hip):\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "metadata": {
        "id": "4lQDiIvQwVkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verify_legs_apart(points)"
      ],
      "metadata": {
        "id": "C6neduGPynuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it detects that the legs are apart"
      ],
      "metadata": {
        "id": "KHDgLfBOytre"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8tGfCNMXyqBA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}